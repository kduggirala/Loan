# Loan

This is the code and other assorted files for a Recurrent Neural Network Loan Prepayment/Default Model I undertook in 2020. The model was intended to read data about a loan's information (data I got from Fannie Mae and Freddie Mac's Single Family Loan-Level Dataset) alongside other macroeconomic variables to predict the loan's deliquency status (i.e. Performing, 30 Days Delinquent, 60 Days Delinquent, 90 Delinquent, Defaulted, Prepaid). Data range from 2000 Q1 to 2019 Q4, and data for each quarter initially came in the form of two files: a performance and an acquisition file. The performance file included data about the performance of the loan, encompassing fields like "CURRENT_INTEREST_RATE", "LOAN_AGE", and "REMAINING_MONTHS_TO_LEGAL_MATURITY". On the other hand, the acquisition file contained information pertaining to the origination of the loan, such as "FIRST_TIME_HOME_BUYER_INDICATOR", "BORROWER_CREDIT_SCORE_AT_ORIGINATION" and "ORIGINAL_DEBT_TO_INCOME_RATIO". For the model, I wanted to combine this data with several other economic variables, such as average house price data from Zillow and unemployment information from the BLS. I wrote code to merge and preprocess this data first on my own laptop (the code and various samples of data for which are in the "loan_model_preprocessing" folder) before moving to AWS to handle the size of the data. I uploaded the data I was working with to a S3 bucket and then used and EMR cluster, first to merge the performance and acquisition data for each loan (this is the joincode.scala file) and then to merge this full data to the economic data (this is newfeatures.scala). 

Then, I got to actually training the models. My first and second attempts at training models can be seen in the first models and second models folders, along with (albeit sometimes chaotic) notes of my thought process as I was training the models. After training my second batch of models, I noticed a problem: my model was getting extremely high accuracy by answering the same answer to every loan (ie. Performing), and since the vast majority of loans followed this pattern, it appeared accurate. This lead me to switch from my old generator function (first_generator.py) develop a generator function that weighted the choice of Performing, Defaulted, and Prepaid mortgages according to their prevalence in the dataset (this is weighted_generator.py). The folder "final models" shows the code for the models that were trained with this new generator function.